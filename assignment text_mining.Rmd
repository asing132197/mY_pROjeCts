---
title: "text mining"
output: html_document
---

# Question (a) 
# Explore the Data

```{r}
library(tidyverse)

resReviewsData <-read_csv2('yelpRestaurantReviews_sample_s21b.csv')
glimpse(resReviewsData)
```
```{r}
# number of reviews by star ratings

resReviewsData %>% group_by(starsReview)%>%count()


```
```{r}
# relation of star ratings with funny,cool,useful

ggplot(resReviewsData,aes(x=funny,y=starsReview))+geom_point()

# star ratings vs cool
ggplot(resReviewsData,aes(x=cool,y=starsReview))+geom_point()

# star ratings vs useful
ggplot(resReviewsData,aes(x=useful,y=starsReview))+geom_point()

# star ratings vs starsBusiness
ggplot(resReviewsData,aes(x=starsBusiness,y=starsReview))+geom_point()

# star cool vs funny
ggplot(resReviewsData,aes(x=cool,y=funny))+geom_point()

```


# Question (b)

```{r}
# want to keep only those review from 5-digit postal code
rrData <- resReviewsData %>% filter(str_detect(postal_code,"^[0-9]{1,5}"))

library(tidytext)
library(SnowballC)
library(textstem)

# tokenize the text of the reviews - keep only review ID,stars review,and text
rrTokens <- resReviewsData %>% select(review_id,starsReview,text) %>%unnest_tokens(word,text)

dim(rrTokens)


```
```{r}
# remove stop words
rrTokens<-rrTokens %>% anti_join(stop_words)
dim(rrTokens)
```


```{r}
# count the total occurences of different words & sort by most frequent
rrTokens%>%count(word,sort=TRUE)%>%top_n(10)
```


```{r}
rareWords <-rrTokens %>%count(word,sort=TRUE)%>%filter(n<10)
rareWords

# remove this rareWords
xx<-anti_join(rrTokens,rareWords)

xx%>%count(word,sort=TRUE)%>%view()

xx<-xx%>%filter(str_detect(word,"[0-9]")==FALSE)
rrTokens <-xx
rrTokens
```


```{r}
# check the word associated with star rating

rrTokens %>% group_by(starsReview)%>%count(word,sort=TRUE)%>%view()

#proportion of word occurrence by star ratings
ws<-rrTokens %>% group_by(starsReview)%>%count(word,sort=TRUE)
ws<-ws%>%group_by(starsReview)%>%mutate(prop=n/sum(n))

#check the proportion of 'love' among reviews with 1,2,..5 stars
ws%>%filter(word=='love')
```
```{r}
#what are the most commonly used words by star rating
ws%>%group_by(starsReview)%>%arrange(starsReview,desc(prop))%>%view()

#to see the top 20 words by star ratings
ws%>%group_by(starsReview)%>%arrange(starsReview,desc(prop))%>%filter(row_number()<=20)%>%view()

# to plot this
ws%>%group_by(starsReview)%>%arrange(starsReview,desc(prop))%>%filter(row_number()<=20)%>%ggplot(aes(word,prop))+geom_col()+coord_flip()+facet_wrap((~starsReview))

```


```{r}
# plot without words like ‘food’, ‘time’,… which occurs across ratings

ws %>% filter(!word %in% c('food','time','restaurant','service'))%>%group_by(starsReview)%>%arrange(starsReview,desc(prop))%>%filter(row_number()<=15)%>% ggplot(aes(word,prop))+geom_col()+coord_flip()+facet_wrap((~starsReview))
```


```{r}
# calculate the average star rating associated with each word

xx <- ws %>% group_by(word) %>% summarise(totWS=sum(starsReview*prop))
xx%>%top_n(20)


```
# Question (C)

# Term Frequency

```{r}
# tokenize, remove stop words, and lemmatize
library(SnowballC)
library(textstem)

rrTokens<-rrTokens %>% mutate(word=textstem::lemmatize_words(word))

# to reduce the number of column filter out those charachter less than 3 and more than 15.

rrTokens <-rrTokens%>%filter(str_length(word)<=3|str_length(word)<=15)

rrTokens<-rrTokens%>%group_by(review_id,starsReview)%>%count(word)

# total number of words in each review
totWords<-rrTokens%>%group_by(review_id)%>% count(word,sort=TRUE)%>%summarise(total=sum(n))

# add the column of join
xx<-left_join(rrTokens,totWords)

xx<-xx%>%mutate(tf=n/total)
xx%>%top_n(20)

rrTokens<-rrTokens%>% bind_tf_idf(word, review_id, n)
```


# Dictionary-1

# With 'bing' 

```{r}
library(textdata)
#get sentiment of words in rrTokens–using join

rrSenti_bing <-rrTokens%>%left_join(get_sentiments("bing"),bye="word")
rrSenti_bing

# retain the word by using inner_join
rrSenti_bing <-rrTokens%>%inner_join(get_sentiments("bing"),bye="word")
rrSenti_bing

```


```{r}
# count the occurrences of positive/negative sentiment words in the reviews
xx<-rrSenti_bing%>%group_by(word,sentiment)%>%summarise(totOcc=sum(n))%>% arrange(sentiment,desc(totOcc))
xx

#negate the counts for the negative sentiment words
xx<-xx%>%mutate(totOcc=ifelse(sentiment=='positive',totOcc,-totOcc))
xx

xx<-ungroup(xx)
xx%>%top_n(25)
xx%>%top_n(-25)

#plot the above values of xx

# the words are not in order
#rbind(top_n(xx, 25), top_n(xx, -25)) %>% ggplot(aes(word, totOcc, fill=sentiment)) +geom_col()+coord_flip()

# with a better reordering of words

rbind(top_n(xx, 25), top_n(xx, -25)) %>% mutate(word=reorder(word,totOcc)) %>% ggplot(aes(word, totOcc, fill=sentiment)) +geom_col()+coord_flip()


```

# Dictionary-2

# With 'nrc' 
```{r}
rrSenti_nrc<-rrTokens%>% inner_join(get_sentiments("nrc"), by="word") %>%
group_by(word, sentiment) %>% summarise(totOcc=sum(n)) %>%
arrange(sentiment, desc(totOcc))

#How many words are there for the different sentiment categories
rrSenti_nrc%>% group_by(sentiment) %>% summarise(count=n(), sumn=sum(totOcc))

#top few words for different sentiments
rrSenti_nrc%>% group_by(sentiment) %>% arrange(sentiment, desc(totOcc))%>% top_n(10) %>% view()


```


# Suppose you want to consider {anger, disgust, fear sadness, negative} to denote 'bad' reviews, and {positive, joy, anticipation, trust} to denote 'good' reviews

```{r}
xx<-rrSenti_nrc%>% mutate(goodBad=ifelse(sentiment %in% c('anger', 'disgust', 'fear', 'sadness', 'negative'), -totOcc, ifelse(sentiment %in% c('positive', 'joy', 'anticipation', 'trust'), totOcc, 0)))

xx<-ungroup(xx)
top_n(xx, -20)
top_n(xx, 20)

rbind(top_n(xx, 20), top_n(xx, -20)) %>% mutate(word=reorder(word,totOcc)) %>% ggplot(aes(word, totOcc, fill=sentiment)) +geom_col()+coord_flip()


```


# Dictionary-3

# With 'AFINN'
```{r}

rrSenti_afinn<-rrTokens%>% inner_join(get_sentiments("afinn"), by="word")

revSenti_afinn<-rrSenti_afinn%>% group_by(review_id, starsReview) %>% summarise(nwords=n(), sentiSum=sum(value))

revSenti_afinn%>% group_by(starsReview) %>% summarise(avgLen=mean(nwords), avgSenti=mean(sentiSum))

revSenti_afinn<-revSenti_afinn%>% mutate(hiLo= ifelse(starsReview <= 2, -1, ifelse(starsReview>=4, 1, 0 )))

revSenti_afinn<-revSenti_afinn%>% mutate(pred_hiLo=ifelse(sentiSum> 0, 1, -1))

xx<-revSenti_afinn%>% filter(hiLo!=0)
table(actual=xx$hiLo, predicted=xx$pred_hiLo)

#revSenti_afinn<-revSenti_afinn%>% mutate(hiLo=ifelse(stars<2,-1, ifelse(stars>4, 1, 0)))

revSenti_afinn<-revSenti_afinn%>% mutate(pred_hiLo=ifelse(sentiSum>0, 1, -1))
xx<-revSenti_afinn%>% filter(hiLo!=0)
table(actual=xx$hiLo, predicted=xx$pred_hiLo)



```
# Question-(d)

```{r}
revDTM_sentiBing<-rrSenti_bing%>% pivot_wider( id_cols= review_id, names_from= word, values_from= tf_idf)

revDTM_sentiBing<-rrSenti_bing%>% pivot_wider(id_cols= c(review_id, starsReview), names_from= word, values_from= tf_idf) %>% ungroup()

dim(revDTM_sentiBing)
```


```{r}

revDTM_sentiBing<-revDTM_sentiBing%>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)

dim(revDTM_sentiBing)


```
# develop Random Forest
```{r}
library(ranger)

revDTM_sentiBing<-revDTM_sentiBing%>% replace(., is.na(.), 0)
revDTM_sentiBing$hiLo<-as.factor(revDTM_sentiBing$hiLo)


library(rsample)
revDTM_sentiBing_split<-initial_split(revDTM_sentiBing, 0.5)
revDTM_sentiBing_trn<-training(revDTM_sentiBing_split)
revDTM_sentiBing_tst<-testing(revDTM_sentiBing_split)

rfModel1<-ranger(dependent.variable.name = "hiLo",
data=revDTM_sentiBing_trn%>% select(-review_id), num.trees= 500,
importance='permutation', probability = TRUE)
```
#Obtain predictions, and calculate performance
```{r}
revSentiBing_predTrn<-predict(rfModel1, revDTM_sentiBing_trn%>% select(-review_id))$predictions
revSentiBing_predTst<-predict(rfModel1, revDTM_sentiBing_tst%>% select(-review_id))$predictions

#Confusion matrix
table(actual=revDTM_sentiBing_trn$hiLo, preds=revSentiBing_predTrn[,2]>0.5)
table(actual=revDTM_sentiBing_tst$hiLo, preds=revSentiBing_predTst[,2]>0.5)



library(pROC)
rocTrn<-roc(revDTM_sentiBing_trn$hiLo, revSentiBing_predTrn[,2], levels=c(-1, 1))
rocTst<-roc(revDTM_sentiBing_tst$hiLo, revSentiBing_predTst[,2], levels=c(-1, 1))
plot.roc(rocTrn, col='blue')
plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"),col=c("blue", "red"), lwd=2, cex=0.8, bty='n')

```


# Remove words which are there in too many or too few of the reviews
```{r}

#First find out how many reviews each word occurs in
rWords<-rrTokens%>% group_by(word)%>% summarise(nr=n()) %>% arrange(desc(nr))

length(rWords$word)

top_n(rWords, 20)
top_n(rWords, -20)

#Suppose we want to remove words which occur in,for eg, > 90% of reviews, and in less than 30 reviews
reduced_rWords<-rWords%>% filter( nr< 6000 & nr> 30)

#reduce the rrTokensdata to keep only the reduced set of words
reduced_rrTokens<-left_join(reduced_rWords, rrTokens)

#next, convert it to a DTM, where each row is for a review (document), and columns are the terms (words)

revDTM<-reduced_rrTokens%>% pivot_wider(id_cols= c(review_id,stars), names_from= word,
values_from= tf_idf) %>% ungroup()

dim(revDTM)

```

```{r}
#create the dependent variable hiLoof good/bad reviews absedon stars, and remove the review with stars=3
revDTM<-revDTM%>% filter(stars!=3) %>% mutate(hiLo=ifelse(stars<=2, -1, 1)) %>% select(-stars)

revDTM<-revDTM%>% replace(., is.na(.), 0)
revDTM$hiLo<-as.factor(revDTM$hiLo)

revDTM_split<-initial_split(revDTM, 0.5)
revDTM_trn<-training(revDTM_split)
revDTM_tst<-testing(revDTM_split)

rfModel2<-ranger(dependent.variable.name = "hiLo", data=revDTM_trn%>% select(-review_id), num.trees= 500, importance='permutation', probability = TRUE)

table(actual=revDTM_trn$hiLo, preds=revDTM_predTrn[,2]>0.5)

table(actual=revDTM_tst$hiLo, preds=revDTM_predTst[,2]>0.5)
```

```{r}
#develop a SVM model on the sentiment dictionary terms
svmM1 <-svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn%>%select(-review_id), kernel="radial", cost=1, scale=FALSE)


#scale is set to TRUE by default. Since all varsare in tfidf, we shudset scale=FALSE
revDTM_predTrn_svm1<-predict(svmM1, revDTM_sentiBing_trn)
revDTM_predTst_svm1<-predict(svmM1, revDTM_sentiBing_tst)table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svm1)

# try different parameters --rbfkernel gamma, and cost
system.time( svmM2 <-svm(as.factor(hiLo) ~., data = revDTM_sentiBing_trn%>% select(-review_id), kernel="radial", cost=5, gamma=5, scale=FALSE) )
revDTM_predTrn_svm2<-predict(svmM2, revDTM_sentiBing_trn)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svm2)
revDTM_predTst_svm2<-predict(svmM2, revDTM_sentiBing_tst)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svm2)
```

# Parameter tuning

```{r}
system.time( svm_tune<-tune(svm, as.factor(hiLo) ~., data = revDTM_sentiBing_trn%>% select(-review_id),kernel="radial", ranges = list( cost=c(0.1,1,10,50), gamma = c(0.5,1,2,5, 10))) )

svm_tune$performances

#Best model
svm_tune$best.parameters
svm_tune$best.model

#predictions from best model
revDTM_predTrn_svm_Best<-predict(svm_tune$best.model, revDTM_sentiBing_trn)
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revDTM_predTrn_svm_Best)
revDTM_predTst_svm_best<-predict(svm_tune$best.model, revDTM_sentiBing_tst)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revDTM_predTst_svm_best)
```


# #develop a naive-Bayes model
```{r}

nbModel1<-naiveBayes(hiLo~ ., data=revDTM_sentiBing_trn%>% select(-review_id))
revSentiBing_NBpredTrn<-predict(nbModel1, revDTM_sentiBing_trn, type = "raw")
revSentiBing_NBpredTst<-predict(nbModel1, revDTM_sentiBing_tst, type = "raw")
table(actual= revDTM_sentiBing_trn$hiLo, predicted= revSentiBing_NBpredTrn[,2]>0.5)
table(actual= revDTM_sentiBing_tst$hiLo, predicted= revSentiBing_NBpredTst[,2]>0.5)
auc(as.numeric(revDTM_sentiBing_trn$hiLo), revSentiBing_NBpredTrn[,2])
auc(as.numeric(revDTM_sentiBing_tst$hiLo), revSentiBing_NBpredTst[,2])


library(pROC)
rocTrn<-roc(revDTM_sentiBing_trn$hiLo, revSentiBing_NBpredTrn[,2], levels=c(-1, 1))
rocTst<-roc(revDTM_sentiBing_tst$hiLo, revSentiBing_NBpredTst[,2], levels=c(-1, 1))
plot.roc(rocTrn, col='blue', legacy.axes= TRUE)plot.roc(rocTst, col='red', add=TRUE)
legend("bottomright", legend=c("Training", "Test"), col=c("blue", "red"), lwd=2, cex=0.8, bty='n')


```


# Question-(e)
```{r}
dim(resReviewsData)
dim(rrData)


x <-rrData %>% select(review_id,attributes)

paste(x[1,2])

x2<-x%>% mutate(atts=str_split(attributes,'\\|'))%>%unnest(atts)
dim(x2)


x3<-x2 %>% cbind(str_split_fixed(x2$atts,":",2))

colnames(x3)[4]<-'attName'
colnames(x3)[5]<-'attValue'


x3 <-x3%>%select(-c(attributes,atts))

x3b <- x3%>%mutate(attName=fct_recode(attName,"NotSpecified"=""))

x3b <-x3%>%mutate(attName=fct_recode(attName,"NotSpecified"=""))

#x3<-x3[!(is.na(x3$attName)|x3$attName==""),]
x4<-x3b %>% pivot_wider( names_from= attName, values_from= attValue)


x5 <-x4 %>% mutate( amb= str_split( Ambience, ","))
extractAmbience<-function(q) {sub(":.*","", q[which(str_extract(q, "True") == "True")])}

x6<-x5 %>% mutate( amb= lapply( amb, extractAmbience))


#how many examples by different values for 'Ambience'

x6 %>% group_by(amb) %>% tally() %>% view()

x6 %>% filter( str_detect(amb, 'casual')) %>% count()

x6 %>% filter( str_detect(amb, 'classy')) %>% count()

# GoodForMeal

x9<-x4 %>% mutate( Meal= str_split( GoodForMeal, ","))
extractGoodForMeal<-function(q) {sub(":.*","", q[which(str_extract(q, "True")=="True")])}

x10<-x9 %>% mutate( Meal= lapply( GoodForMeal,extractGoodForMeal))

x10 %>% group_by(Meal) %>% tally() %>% view()


#For Alcohol
x4 %>% group_by(Alcohol) %>%tally() %>% view()

#For Noise Level
x4 %>% group_by(NoiseLevel) %>% tally() %>% view()

# for Business Parking

x11<-x4 %>% mutate( BusPark= str_split(BusinessParking, ","))
extractBusinessParking<-function(q) {sub(":.*","", q[which(str_extract(q, "True")=="True")])}

x12<-x11 %>% mutate(BusinessParking = lapply(BusinessParking,extractBusinessParking))

x12 %>% group_by(BusPark) %>% tally() %>% view()


x7<- x6%>% select(review_id,amb)
x7<-x7 %>% filter( str_detect (amb, 'upscale'))
starsreviewall1<- rrData %>% select (review_id,starsReview)%>% left_join(x7, by = "review_id")
starsreviewall1<- starsreviewall1%>%filter(amb != 'NULL')
stars1n<-starsreviewall1 %>% group_by(starsReview) %>% count() 
stars1left<-stars1n%>%select (starsReview,n)%>% left_join(stars1n, by = "starsReview") 
stars1left$total_review <- stars1n$n
stars1left$total_upscale <- stars1n$n
stars1left$percent = paste(round((stars1left$total_upscale / stars1left$total_review)*100,2), "%", sep="")
stars1left %>% select(starsReview, total_upscale, total_review, percent)%>%view()

x8<- x6%>% select(review_id,amb)
x8<-x8 %>% filter( str_detect (amb, 'classy'))
starsreviewall2<- rrData %>% select (review_id,starsReview)%>% left_join(x8, by = "review_id") 
starsreviewall2<- starsreviewall2 %>%filter(amb != 'NULL')
stars2n<-starsreviewall2 %>% group_by(starsReview) %>% count() 
stars12left<-stars2n%>%select (starsReview,n)%>% left_join(stars2n, by = "starsReview")
stars12left$total_review <- stars2n$n
stars12left$total_classy <- stars2n$n
stars12left$percent = paste(round((stars12left$total_classy / stars12left$total_review)*100,2), "%", sep="")
stars12left %>% select(starsReview, total_classy, total_review, percent)%>% view()





```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
